<h1>Results</h1>

Since there was no change to the physics of the problem that has first been analyzed
in step-15, there is nothing to report about that. The only outwardly noticeable 
difference between them is that, by default, this program will only run 9 mesh
refinement steps (as opposed to step-15, which executes 11 refinements).
This will be observable in the simulation status that appears between the
header text that prints which assembly method is being used, and the final
timings.

```
Mesh refinement step 0
  Initial residual: 1.53143
  Residual: 1.08746
  Residual: 0.966748
  Residual: 0.859602
  Residual: 0.766462
  Residual: 0.685475

...

Mesh refinement step 9
  Initial residual: 0.00924594
  Residual: 0.00831928
  Residual: 0.0074859
  Residual: 0.0067363
  Residual: 0.00606197
  Residual: 0.00545529
```

So what is interesting for us to compare is how long the assembly process takes
for the three different implementations, and to put that into some greater context.
Below is the output for the hand linearization (as computed on a circa 2012
eight-core laptop):
```
******** Assembly approach ********
Unassisted implementation (full hand linearization).

...

+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      35.1s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble                        |        50 |      1.56s |       4.5% |
| Solve                           |        50 |      30.8s |        88% |
+---------------------------------+-----------+------------+------------+
```
And for the implementation that linearizes the residual in an automated
manner using the Sacado dynamic forward AD number type:
```
******** Assembly approach ********
Automated linearization of the finite element residual.

...

+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      40.1s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble                        |        50 |       8.8s |        22% |
| Solve                           |        50 |      28.6s |        71% |
+---------------------------------+-----------+------------+------------+
```
And, lastly, for the implementation that computes both the residual and
its linearization directly from an energy functional (using nested Sacado
dynamic forward AD numbers):
```
******** Assembly approach ********
Automated computation of finite element residual and linearization using a variational formulation.

...

+---------------------------------------------+------------+------------+
| Total wallclock time elapsed since start    |      48.8s |            |
|                                             |            |            |
| Section                         | no. calls |  wall time | % of total |
+---------------------------------+-----------+------------+------------+
| Assemble                        |        50 |      16.7s |        34% |
| Solve                           |        50 |      29.3s |        60% |
+---------------------------------+-----------+------------+------------+
```

It's evident that the more work that is passed off to the automatic differentiation
framework to perform, the more time is spent during the assembly process. Accumulated
over all refinement steps, using one level of automatic differentiation resulted
in $5.65 \times$ more computational time being spent in the assembly stage when
compared to unassisted assembly, while assembling the discrete linear system took
$10.7 \times$ longer when deriving directly from the energy functional.
Unsurprisingly, the overall time spend solving the linear system remained unchanged.
This means that the proportion of time spent in the solve phase to the assembly phase
shifted significantly as the number of times automated differentiation was performed
at the finite element level. For many, this might mean that leveraging higher-order
differentiation (at the finite element level) in production code leads to an
unacceptable overhead, but it may still be useful during the prototyping phase.
A good compromise between the two may, therefore, be the automated linearization
of the finite element residual, which offers a lot of convenience at a measurable,
but perhaps not unacceptable, cost. 

Of course, the actual overhead is very much dependent on the problem being evaluated
(e.g., how many components there are in the solution, what the nature of the function
being differentiated is, etc.). So the exact results presented here should be
interpreted within the context of this scalar problem alone, and when it comes to
other problems some preliminary investigation by the user is certainly warranted.


<h3> Possibilities for extensions </h3>

Like step-71, there are a few items related to automatic differentiation that could
be evaluated further:
- The use of other AD frameworks should be investigated, with the outlook that
  alternative implementations may provide performance benefits.
- It is also worth evaluating AD number types other than those that have been
  hard-coded into this tutorial. With regard to twice differentiable types
  employed at the finite-element level, mixed differentiation modes (RAD-FAD)
  should in principle be more computationally efficient than the single
  mode (FAD-FAD) types employed here. The reason that the RAD-FAD type was not
  selected by default is that, at the time of writing, there remain some
  bugs in its implementation within the Sacado library that lead to memory leaks.
  This is documented in the @ref auto_symb_diff module.
- It might be the case that using reduced precision types (i.e., `float`) as the
  scalar types for the AD numbers could render a reduction in computational
  expense during assembly.
- One further method of possibly reducing resources during assembly is to frame
  the AD implementations as a constitutive model. This would be similar to the
  approach adopted in step-71, and pushes the starting point for the automatic
  differentiation one level higher up the chain of computations. This, in turn,
  means that less operations are tracked by the AD library, thereby reducing the
  cost of differentiating (even though one would perform the differentiation at
  each cell quadrature point). 
