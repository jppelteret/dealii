<a name="Intro"></a>
<h1>Introduction</h1>

Topology Optimization of Elastic Media is a technique used to optimize a
structure that is bearing some load. Ideally, we would like to minimize the
maximum stress placed on a structure by selecting a region $E$ where material is
placed. In other words,
@f[
  \text{Minimize}\norm{\sigma (\textbf{u}) }_\infty
@f]
@f[
  \text{subject to } |E|\leq V_{\max},
@f]
@f[
  \text{and } \nabla \cdot \sigma +\textbf{ F} = 0.
@f]
Here, $\sigma=C\varepsilon(\mathbf u)$ is the stress within the body that is
caused by the external forces $\mathbf F$, where we have for simplicity assumed
that the material is linear-elastic and so $C$ is the stress-strain tensor and
$\varepsilon(\mathbf u)=\frac 12 (\nabla \mathbf u + \nabla\mathbf u^T)$ is the
small-deformation strain as a function of the displacement $\mathbf u$ -- see
step-8 and step-17 for more on linear elasticity. In the formulation above,
$V_\text{max}$ is the maximal amount of material we are willing to provide to
build the object. The last of the constraints is the partial differential
equation that relates stress $\sigma$ and forces $\mathbf F$ and is simply the
stead-state force balance.

That said, the infinity norm above creates a problem: As a function of location
of material, this objective function is necessarily not differentiable, making
prospects of optimization rather bleak. So instead, a common approach in
topology optimization is to find an approximate solution by optimizing a related
problem: We would like to minimize the strain energy, or compliance. This is a
measure of the potential energy stored in an object due to its deformation, but
also works as a measure of total displacement over the structure.

@f[
  \text{Minimize  } \int_E \frac{1}{2}\sigma : \epsilon
@f]
@f[
  \text{subject to } \norm{E}\leq V_{\max}
@f]
@f[
  \text{and } \nabla \cdot \sigma + \textbf{F} = 0
@f]

The value of the objective function is calculated using a finite element method,
where the solution is the displacements. This is placed inside of a nonlinear
solver loop that solves for a vector denoting placement of material.

<h3>Solid Isotropic Material with Penalization</h3>

In actual practice, we can only build objects in which the material is either
present, or not present, at any given point -- i.e., we would have an indicator
function $\rho_E(\mathbf x)\in \{0,1\}$ that describes the material-filled
region and that we want to find through the optimization problem. In this case,
the optimization problem becomes combinatorial, and very expensive to solve.
Instead, we use an approach called Solid Isotropic Material with Penalization,
or SIMP. @cite Bendse2004

The SIMP method is based off of an idea of allowing the material to exist in a
location with a density $\rho$ between 0 and 1. A density of 0 suggests the
material is not there, and it is not a part of the structure, while a density of
1 suggests the material is present. Values between 0 and 1 do not reflect
real-world phenomena, but allow us to turn the combinatorial problem into a
continuous one. One then looks at density values $\rho$, with the constraint
that $0 < \rho_{\min} \leq \rho \leq 1$. The minimum value $\rho_{\min}$,
typically chosen to be around $10^{-3}$, avoids the possibility of having an
infinite compliance, but is small enough to provide accurate results.

The straightforward application of the effect of this "density" on the
elasticity of the media would be to simply multiply the stiffness tensor $C_0$
of the medium by the given density, that is, $C = \rho C_0$. However, this
approach often gives optimal solutions where density values are far from both 0
and 1. As one wants to find a real-world solution, meaning the material either
is present or it is not, a penalty is applied to these in-between values. A
simple and effective way to do this is to multiply the stiffness tensor by the
density raised to some integer power penalty parameter $p$, so that
$C = \rho^p C_0$. This makes density values farther away from 0 or 1 less
effective. It has been shown that using $p=3$ is sufficiently high to create
'black-and-white' solutions: that is, one gets optimal solutions in which
material is either present or not present at all points.

More material should always provide a less compliant structure, and so the
inequality constraint can be viewed as an equality, where the total volume used
is the maximum volume.

Using this density idea also allows us to reframe the volume constraint on the
optimization problem. Use of SIMP then turns the optimization problem into the
following:

@f[
  \text{Minimize  } \int_\Omega \frac{1}{2}\sigma(\rho) : \epsilon(\rho)
@f]
@f[
  \text{subject to } \int_\Omega \rho(x) = V_{\max},
@f]
@f[
  0<\rho_{\min}\leq \rho(x) \leq 1,
@f]
@f[
  \nabla \cdot \sigma(\rho) + \mathbf{F} = 0
@f]
The final constraint, the elasticity equation, gives a method for finding
$\sigma$ and $\epsilon$ given the density $\rho$.


<h3>Elasticity Equation</h3>
The elasticity equation in the time independent limit reads
@f[
  \nabla \cdot \sigma + \textbf{F} = 0.
@f]
In the situations we will care about, we will assume that the medium is linear
and in that case, we have that
@f[
  \sigma = C \varepsilon = \rho^p C_0 \varepsilon(\mathbf u)
   = \rho^p C_0 \left[\frac 12 (\nabla \mathbf u + \nabla \mathbf u^T) \right],
@f]
and in everything we will do below, we will always consider the displacement
field $\mathbf u$ as the only solution variable, rather than considering
$\mathbf u$ and $\sigma$ as solution variables (as is done in mixed
formulations).

Furthermore, we will make the assumption that the material is linear isotropic,
in which case the stress-strain tensor can be expressed in terms of the Lam\'{e}
 parameters $\lambda,\mu$ such that
@f[
  \sigma = \rho^p (\lambda tr(\epsilon) I + 2 \mu \epsilon)
@f]
@f[
  \sigma_{i,j} = \rho^p (\lambda  \epsilon_{k,k} \delta_{i,j}
  + 2 \mu \epsilon_{i,j})
@f]
see step-8 for how this transformation works.

Integrating the objective function by parts, along with using the elasticity
equation constraint, gives a simplification of the objective problem as follows:

@f[
  \int_\Omega \sigma(\rho) : (\nabla \textbf{u} + (\nabla \textbf{u})^T) +
  \int_\Omega (\nabla \cdot \sigma(\rho)) \cdot \textbf{u} =
  \int_{\partial \Omega} \textbf{t} \cdot \textbf{u}
@f]

@f[
  \int_\Omega \sigma(\rho) : (\nabla \textbf{u} + (\nabla u)^T) =
  \int_\Omega \textbf{F}\cdot \textbf{u} +
  \int_{\partial \Omega} \textbf{t} \cdot \textbf{u}
@f]

Because we are assuming no internal forces, this simplifies all the way to

@f[
  \int_\Omega \sigma(\rho) : (\nabla \textbf{u} + (\nabla \textbf{u})^T)
  = \int_{\partial \Omega} \textbf{t} \cdot \textbf{u}
@f]

<h3>Making the solution mesh-independent</h3>

Typically, the solutions to topology optimization problems are not
mesh-independent, and as such the problem is ill-posed. This is because as the
mesh is refined further, fractal structures are often formed. As the mesh gains
resolution, the optimal solution typically gains smaller and smaller structures.
There are a few competing work-arounds to this issue, but the most popular for
first order optimization is the sensitivity filter, while second order
optimization methods tend to prefer use of a density filter.

As the filters affect the gradient and Hessian of the compliance (i.e., the
objective function), the choice of filter has an effect on the solution of the
problem. The density filter as part of a second order method works by
introducing an unfiltered density, which I refer to as $\sigma$, and then
requiring that the density be a convolution of the unfiltered density:
@f[
  \rho = H(\sigma).
@f]
Here, $H$ is an operator so that $\rho(\mathbf x)$ is some kind of average of
the values of $\sigma$ in the area around $\mathbf x$ -- i.e., it is a smoothed
version of $\sigma$.

This prevents checkerboarding; the radius of the filter allows the user to
define an effective minimal beam width for the optimal structures we seek to
find.

<h3>Complete Problem Formulation</h3>

The minimization problem is now
@f[
  \min_{\rho,\sigma,\mathbf u} \int_{\partial\Omega} \textbf{u} \cdot \textbf{t}
@f]
@f[
  \text{s.t.   } \rho = H(\sigma)
@f]
@f[
  \int_\Omega \rho^p \left(\frac{\mu}{2}\left(\epsilon(\textbf{v}):
  \epsilon(\textbf{u})) \right) + \lambda \left( \nabla \cdot \textbf{u} \nabla
  \cdot \textbf{v} \right)  \right) = \int_{\partial \Omega} \textbf{v} \cdot
  \textbf{t}
@f]
@f[
  \int_\Omega \rho = V
@f]
@f[
  0\leq \sigma \leq 1
@f]

The inequality constraints are dealt with by first introducing slack variables,
and second using a log barriers to ensure that we obtain an interior-point
method. The penalty parameter is going to be $\alpha$, and the following slack
variables
<ol>
    <li> $s_1$ - a slack variable corresponding to the lower bound</li>
    <li> $s_2$ - a slack variable corresponding to the upper bound</li>
</ol>
This now gives the following problem:
@f[
  \min_{\rho,\sigma,\mathbf u, s_1, s_2} \int_{\partial\Omega} \textbf{u} \cdot
  \textbf{f} - \alpha \int_\Omega \left(\log(s_1) + \log(s_2)\right)
@f]
@f[
  \text{s.t.   } \rho = H(\sigma)
@f]
@f[
  \int_\Omega \rho^p \left(\frac{\mu}{2}\left(\epsilon(\textbf{v}):
  \epsilon(\textbf{u})) \right) + \lambda \left( \nabla \cdot \textbf{u} \nabla
  \cdot \textbf{v} \right)  \right) = \int_{\partial \Omega} \textbf{v} \cdot
  \textbf{f}
@f]
@f[
  \int_\Omega \rho = V
@f]
@f[
  \sigma = s_1
@f]
@f[
  1-\sigma = s_2
@f]

With these variables in place, we can then follow the usual approach to solving
constrained optimization problems: We introduce a Lagrangian in which we combine
 the objective function and the constraints by multiplying the constraints by
 Lagrange multipliers. Specifically, we will use the following symbols for the
 Lagrange multipliers for the various constraints:
<ol>
    <li> $\textbf y_1 $ - a Lagrange multiplier corresponding to the
    elasticity constraint </li>
    <li> $y_2$ - a Lagrange multiplier corresponding to the convolution
    filter constraint </li>
    <li> $z_1$ - a Lagrange multiplier corresponding to the lower slack </li>
    <li> $z_2$ - a Lagrange multiplier corresponding to the upper slack </li>
</ol>
With these variables, the Lagrangian function reads as follows:

@f{multiline}{
  \mathcal{L} = \int_{\partial\Omega} \textbf{u} \cdot \textbf{f}
   - \alpha \int_\Omega \left(\log(s_1) + \log(s_2)\right) -  \left(\int_\Omega
   \rho^p \left(\frac{\mu}{2}\left(\epsilon(\textbf{y}_1):\epsilon(\textbf{u}))
   \right) + \lambda \left( \nabla \cdot \textbf{u} \nabla \cdot \textbf{y}_1
   \right)  \right)- \int_{\partial \Omega} \textbf{y}_1 \cdot \textbf{f}\right)
   \\- y_2 (\rho - H(\sigma)) - z_1 (\sigma-s_1) - z_2 (1 - s_2 -\sigma)
@f}

The solution of the optimization problem then needs to satisfy what are known as
 the Karush-Kuhn-Tucker (KKT) conditions: The derivatives of the Lagrangian with
  respect to all of its arguments need to be equal to zero, and because we have
  inequality constraints, we also have "complementarity" conditions. Since we
  here have an infinite-dimensional problem, these conditions all involve
  directional derivatives of the Lagrangian with regard to certain test
  functions -- in other words, all of these conditions have to be stated in weak
   form as is typically the basis for finite element methods anyway.

The barrier method allows us to initially weaken the ``complementary slackness"
as required by the typical KKT conditions. Typically, we would require that
$s_i z_i = 0$, but the barrier formulations give KKT conditions where
$s_i z_i = \alpha$, where $\alpha$ is our barrier parameter. As part of the
barrier method, this parameter must be driven close to 0 to give a good
approximation of the original problem.

In the following, let us state all of these conditions where
$d_{\{\cdot\}}$ is a test function that is naturally paired with the
$\{\cdot\}$ function.
<ol>
<li> Stationarity:
@f[
  \int_\Omega  - d_\rho y_2 + p\rho^{p-1}d_\rho \left[\lambda
  (\nabla \cdot \textbf{y}_1) (\nabla \cdot \textbf{u}) +
  \mu \varepsilon(\textbf{u}):\varepsilon(\textbf{y}_1)\right]=0\;\;
  \forall d_\rho
@f]
@f[
  \int_\Gamma \mathbf d_\textbf{u} \cdot \textbf{f} + \int_\Omega p\rho^{p}
  \left[\lambda (\nabla \cdot \mathbf d_\textbf{u})( \nabla \cdot \textbf{y}_1)
  + \mu \varepsilon(\mathbf d_\textbf{u}):\varepsilon(\textbf{y}_1)\right]=0\;\;
  \forall \textbf{d}_\textbf{u}
@f]
@f[
  \int_\Omega -d_\sigma z_1 + d_\sigma z_2 + H(d_\sigma)y_2 = 0\;\;\forall
  d_\sigma
@f]
</li>
<li> Primal Feasibility:
    @f[
      \int_\Omega \rho^{p}\lambda (\nabla \cdot \mathbf d_{\textbf{y}_1})
      (\nabla \cdot \textbf{u}) +  \rho^{p}\mu  \varepsilon(\mathbf
      d_{\textbf{y}_1}) : \varepsilon(\textbf{u}) - \int_\Gamma \mathbf
      d_{\textbf{y}_1} \cdot \textbf{f} =0 \;\;\forall \textbf{d}_{\textbf{y}_1}
    @f]
    @f[
      \int_\Omega d_{z_1}(\sigma - s_1) = 0\;\;\forall d_{z_1}
    @f]
    @f[
      \int_\Omega d_{z_z}(1-\sigma-s_2) = 0\;\;\forall d_{z_2}
    @f]
    @f[
      \int_\Omega d_{y_2}(\rho - H(\sigma)) = 0\;\;\forall d_{y_2}
    @f]
</li>
<li>Complementary Slackness:
    @f[
      \int_\Omega d_{s_1}(s_1z_1 - \alpha) = 0 \;\;\forall d_{s_1} ,\;\;\;
      \alpha \to 0
    @f]
    @f[
      \int_\Omega d_{s_2}(s_2z_2 - \alpha) = 0  \;\;\forall d_{s_2} ,\;\;\;
      \alpha \to 0
    @f]
</li>
<li> Dual Feasibility:
    @f[
      s_{1,i},s_{2,i},z_{1,i},z_{2,i} \geq 0 \;\;\;\; \forall i
    @f]
</li>
</ol>

<h3>Solution procedure</h3>

The optimality conditions above are, in addition to being convoluted, of a kind
that is not easy to solve: They are generally nonlinear, and some of the
relationships are also inequalities. We will address the nonlinearity using a
Newton method to compute search directions, and come back to how to deal with
the inequalities below when talking about step length procedures.

Newton's method applied to the equations above results in the following system.
Here, variational derivatives with respect to the $\{\cdot\}$ variable are taken
 in the $c_{\{\cdot\}}$ direction. This gives

<ol>
<li> Stationarity - these equations ensure we are at a critical point of the
objective function when constrained

Equation 0
@f{multiline}{
  \int_\Omega-d_\rho c_{y_2} + p(p-1) \rho^{p-2} d_\rho c_\rho [\lambda \nabla
  \cdot \textbf{y}_1 \nabla \cdot \textbf{u} +  \mu  \varepsilon(\textbf{u})
  \varepsilon(\textbf{y}_1)] @f]@f[+ p \rho^{p-1} d_\rho[\lambda \nabla \cdot
  \textbf{c}_{\textbf{y}_1} \nabla \cdot \textbf{u} +   \mu  \varepsilon
  (\textbf{u}) \varepsilon(\textbf{c}_{\textbf{y}_1})]  +  p \rho^{p-1} d_\rho
  [\lambda \nabla \cdot {\textbf{y}_1} \nabla \cdot \textbf{c}_\textbf{u} +
  \mu  \varepsilon(\textbf{c}_\textbf{u}) \varepsilon(\textbf{y}_1)]
 \\=-\int_\Omega -d_\rho z_1 + d_\rho z_2 - d_\rho y_2 + p\rho^{p-1}d_\rho
[\lambda \nabla \cdot \textbf{y}_1 \nabla \cdot \textbf{u} + \mu \varepsilon
(\textbf{u})\varepsilon(\textbf{y}_1)]
@f}

Equation 1
@f{multiline}{
  \int_\Omega p \rho^{p-1} c_\rho [\lambda \nabla \cdot {\textbf{y}_1} \nabla
  \cdot \textbf{d}_\textbf{u} +  \mu  \varepsilon(\textbf{d}_\textbf{u})
  \varepsilon(\textbf{y})] + \rho^{p} [\lambda \nabla \cdot
  \textbf{c}_{\textbf{y}_1} \nabla \cdot \textbf{d}_\textbf{u} +  \mu
  \varepsilon(\textbf{d}_\textbf{u})\varepsilon(\textbf{c}_{\textbf{y}_1})]
\\
=-\int_\Gamma \textbf{d}_\textbf{u} \cdot \textbf{f} -\int_\Omega \rho^{p}
[\lambda \nabla \cdot \textbf{y} \nabla \cdot \textbf{d}_\textbf{u} + \mu
\varepsilon(d_\textbf{u})\varepsilon(\textbf{y}_1)]
@f}
Equation 2
@f[
  \int_\Omega  - d_\sigma c_{z_1} +d_\sigma c_{z_2}  + H(d_\sigma)c_{y_2} =
  -\int_\Omega -d_\sigma z_1 + d_\sigma z_2 + H(d_\sigma)y_2
@f]
</li>
<li> Primal Feasibility - these equations ensure the equality constraints
are met.

Equation 3
@f{multiline}{\int_\Omega p \rho^{p-1} c_p[\lambda \nabla \cdot
\textbf{d}_{\textbf{y}_1} \nabla \cdot \textbf{u} +  \mu
\varepsilon(\textbf{u}) \varepsilon(\textbf{d}_{\textbf{y}_1})] +
\rho^{p}[\lambda \nabla \cdot \textbf{d}_{\textbf{y}_1} \nabla \cdot
\textbf{c}_\textbf{u} +  \mu  \varepsilon(\textbf{c}_\textbf{u})
\varepsilon(\textbf{d}_{\textbf{y}_1})]
\\
 =-\int_\Omega \rho^{p}[\lambda \nabla \cdot \textbf{d}_{\textbf{y}_1} \nabla
 \cdot \textbf{u} + \mu  \varepsilon(\textbf{u}) \varepsilon
 (\textbf{d}_{\textbf{y}_1})]  + \int_\Gamma  \textbf{d}_{\textbf{y}_1}
 \cdot \textbf{f}
@f}

    Equation 4
@f[
  -\int_\Omega d_{z_1}(c_\sigma - c_{s_1})=\int_\Omega d_{z_1} (\sigma - s_1)
@f]

    Equation 5
@f[
  -\int_\Omega d_{z_2}(-c_\sigma-c_{s_2}) = \int_\Omega d_{z_2} (1-\sigma-s_2)
@f]

    Equation 6
@f[
  -\int_\Omega   d_{y_2}(c_\rho - H(c_\sigma))=\int_\Omega d_{y_2}
  (\rho - H(\sigma))
@f]
  <\li>
  <li>Complementary Slackness - these equations essentially ensure the barrier
  is met - in the final solution, we need $s^T z = 0$
    Equation 7
    @f[
      \int_\Omega d_{s_1}(c_{s_1}z_1/s_1 +  c_{z_1} )=-\int_\Omega d_{s_1}
      (z_1 - \alpha/s_1) ,\;\;\; \alpha \to 0
    @f]

    Equation 8
    @f[
      \int_\Omega d_{s_2} (c_{s_2}z_2/s_2 + c_{z_2} )=-\int_\Omega d_{s_2}
      (z_2 - \alpha/s_2) ,\;\;\; \alpha \to 0
    @f]

    Dual Feasibility - Multiplier on slacks and slack variables must be kept
    greater than 0. (This is the only part not implemented in the
    "assemble\_block\_system()" function)
    @f[
      s,z \geq 0
    @f]
    <\li>
</ol>



<h3>Discretization</h3>
I use a quadrilateral mesh with $Q_1$ element to discretize the displacement and
 displacement Lagrange multiplier. Piecewise constant $DGQ_0$ elements are used
 to discretize the density, unfiltered density, density slack variables, and
 multipliers for the slack variables and filter constraint.

<h3>Nonlinear Algorithm</h3>

While most of the discussion above follows traditional and well-known approaches
 to solving nonlinear optimization problems, it turns out that the problem is
 actually quite difficult to solve in practice. In particular, it is quite
 nonlinear and an important question is not just to find search directions
 $c_\bullet$ as discussed above based on a Newton method, but that one needs to
 spend quite a lot of attention to how far one wants to go in this direction.
 This is often called ``line search" and comes down to the question of how to
 choose the step length $\alpha_k \in (0,1]$ so that we move from the current
 iterate $x_k$ to the next iterate $x_{k+1}=x_k+\alpha_k x_k$ in as efficient a
 way as possible. It is well understood that we need to eventually choose
 $\alpha_k=1$ to realize the Newton's method's quadratic convergence; however,
 in the early iterations, taking such a long step might actually make things
 worse, either by leading to a point that has a worse objective function or at
 which the constraints are satisfied less well than they are at $x_k$.

Very complex algorithms have been proposed to deal with this issue.
@cite Nocedal2009 @cite Wchter2005 Here, we implement a watchdog-search
algorithm.@cite Nocedal2006 When discussing this algorithm, I will use the
vector $\textbf{x}$ to represent all primal variables - the filtered and
unfiltered densities, slack variables and displacement - and use the vector
$\textbf{y}$ to represent all of the dual vectors. The solution to the Newton
System above will now be referred to as $\Delta \textbf{x}$ and $\Delta
\textbf{y}$ instead of $c_{\{\cdot\}}$. A merit function is referred to here as
$\phi(\textbf{x,\textbf{y}})$

The watchdog algorithm applied to a subproblem with a given barrier parameter
works in the following way: First, the current iteration is saved as a
"watchdog" state, and the merit of the watchdog state is recorded.
A maximal feasibel newton step is then taken. If the merit sufficiently
decreased from the first step, this new step is accepted. If not, another
maximal feasible newton step is taken, and the merit is again compared to the
watchdog merit.
If after some number (typically betwteen 5 and 8) of newton steps, the merit did
 not adequately decrease, the algorithm takes a scaled newton step from either
 the watchdog state or the last iteration that guarantees
a sufficient decrease of the merit, and that step is accepted. Once a step is
accepted, the norm of the KKT error is measured, and if it is sufficiently
small, the barrier value is decreased. If it is not sufficiently small, the
last accepted step is taken to be the new watchdog step, and the process is
repeated.


Above, the ``maximal feasible step" is a scaling of the newton step in both the
primal and dual variables given by

@f[
  \beta^\textbf{y} = \min\{1,\max \beta \text{ such that }\left(\textbf{z}_{k+i}
   + \beta^\textbf{z}_{k+i} \Delta \textbf{z}_{k+i}\right)_j \geq \zeta
   \textbf{z}_{k+i,j} \forall j\}
@f]
@f[
  \beta^\textbf{x} = \min\{1,\max \beta \text{ such that }\left(\textbf{s}_{k+i}
   + \beta^\textbf{s}_{k+i} \Delta \textbf{s}_{k+i}\right)_j \geq \zeta
   \textbf{s}_{k+i,j} \forall j\}
@f]

Above, $\zeta$ is the "fraction to boundary" that is allowed on any step.
Because the derivatives become ill-conditioned near the boundary, this technique
 stands in for a trust region and is necessary to ensure good approximations in
 the future. $\zeta$ is taken to be $\max\{.8, 1-\alpha\}$, which allows
 movement closer to the boundary as the barrier becomes smaller. In the future,
 when implementing the LOQO algorithm for barrier reduction, this must be kept
 to .8 as the barrier parameter can vary wildly.

Separately, we need to deal with the log-barrier that we have used to enforce
the positivity constraint on the slack variables $s_1,s_2$: In the statement of
the final optimization problem we solve, we have added the term
@f[
  -\alpha \int_\Omega (\log(s_1) + \log(s_2)).
@f]
The question is how we should choose the penalty factor $\alpha$. As with all
penalty methods, we are in reality only interested in the limit as
$\alpha\to 0$, since this is then the problem we really wanted to solve,
subject to the positivity constraints on the slack variables. On the other hand,
 we need to choose $\alpha$ large enough to make the problem solvable in
 practice. Actual implementations therefore start with a larger value of
 $\alpha$ and gradually decrease it as the outer iterations proceed.

In the monotone method implemented here, the barrier parameter is updated
whenever some level of convergence is achieved at the current barrier parameter.
 I use the $l_\infty$ norm of the KKT conditions to check for convergence at
 each barrier size. The requirement is that
 $\norm{KKT}_{l_\infty} < c \cdot \alpha$ where $c$ is a constant over any
 barrier size and $\alpha$ is the barrier parameter. This forces better
 convergence in later iterations, and is the same requirement as is used in
 IPOPT.

Here, the barrier is reduced linearly at larger values, and superlinearly at
smaller values. At larger values, it is multiplied by a constant (around .6),
and at lower values the barrier value is replaced by the barrier value raised
to some exponent (around 1.2). This method has proven to be effective at keeping
 the subproblem solvable at large barrier values, while still allowing
 superlinear convergence at smaller barrier values.
@f[
  \alpha_{k+1} = \min\{\alpha_k^{1.2},.6\alpha_k\}
@f]

While taking large steps at reducing the barrier size when convergence is
reached is widely used, more recent research has shown that it typically faster
to use algorithms that adaptively update barrier each iteration, i.e., in which
we use concrete criteria at the end of each iteration to determine what the
penalty parameter should be in the next iteration, rather than using reduction
factors that are independent of the current solution. That said, such methods
are also more complicated and we will not do this here.

<h3>Merit Function</h3>

The algorithm outlined above makes use of a "merit function". Merit functions
are used to determine whether a step from $x_k$ to a proposed point $x_{k+1}$ is
 beneficial. In unconstrained optimization problems, one can simply check this
 with the object function we try to minimize, and typically uses conditions such
  as the Wolfe and Goldstein conditions.

In constrained optimization problems, the question is how to balance reduction
in the objective function against a possible increase in the violation of
constraints: A proposed step might make the objective function smaller but be
further away from the set of points that satisfy the constraints -- or the other
 way around. This trade-off is typically resolved by using a merit function that
  combines the two criteria.

Here, we use an exact $l_1$ merit function to test the steps.
@f{multiline}{
  \phi(\textbf{x},\textbf{y}) = \int_{\partial \Omega} \textbf{u}\cdot
  \textbf{t} - \alpha \int_\Omega (log(s_1) + log(s_2)) + p \sum_i\left|
  \int_\Omega y_{2,i}(H(\sigma) - \rho) \right|
\\
+ p \sum_i\left| \int_{\partial \Omega} \textbf{y}_{1,i}\cdot \textbf{t}  -
\int_\Omega \rho^p[\lambda \nabla \cdot \textbf{u} \nabla \cdot \textbf{y}_{1,i}
 + \mu \varepsilon{\textbf{u}}\varepsilon{\textbf{y}_{1,i}}]\right|
\\
+ p \sum_i\left| \int_\Omega z_{1,i}(s_1 - \sigma) \right|+ p \sum_i\left|
\int_\Omega z_{2,i}(1-\sigma - s_2) \right|
@f}

Here, $p$ is a penalty parameter. This merit function being exact means that
there exists some $p_0$ so that for any $p > p_0$, the merit function has its
minima at the same location as the original problem. This penalty parameter is
updated (by recommendation of Nocedal and Wright) @cite Benson2002
@f[
  p > \frac{.5 x^T H x - x^t\nabla f}{\norm{c_i}_{l_\infty}, i \in \mathcal{E}}
@f]
Where $H$ is the hessian of the objective function, $x$ is a vector of our
decision variables, $f$ is the objective function, and $c_i$ is the error on a
current equality constraint.

My use of this method is partially due to already having most of the necessary
parts calculated in finding the right hand side, but also the use of an exact
merit function ensures that it is minimized in the same location as the overall
problem. Recent research has shown that one can replace merit functions by what
are called "filter methods", and one should consider using these instead as they
 prove to be more efficient.
